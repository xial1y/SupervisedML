{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description:\n",
    "\n",
    "Beta Bank, due to the gradual leaving of their clients, is interested in creating a machine learning model that will predict whether a customer will leave or stay with the bank since it is cheaper to retain a customer than to find a new one. We are given a dataset with their clients' past behavior and contract terminatations that will be divided and used for model training and testing. The model that will be considered successful will need to have a testing set F1 score of at least 0.59. We are requested to compare the F1 score with the AUC-ROC metric. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset \n",
    "try:\n",
    "    df = pd.read_csv(\"/Users/sallyhuang/Downloads/Churn.csv\") \n",
    "except:\n",
    "    df = pd.read_csv(\"/datasets/Churn.csv\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing dataframe; there are some columns that we don't think is needed and should be dropped as it does not likely contribute to the prediction like row number, customerid number, and their surnames, those factors will not affect whether they decide to stay with Beta Bank or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the columns\n",
    "\n",
    "df = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df now have 11 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking for duplicates in df dataframe and lastly we will need to check for missing values before working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values \n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked for missing values in the df dataframe and see that the Tenure column has MANY missing values so we will be filling in the missing values with the mean Tenure value because it is a column that is needed because it could be an factor that affects whether a client would leave or not and should be retained instead of just droppping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].mean()) \n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to fill the missing values with the mean value of the Tenure column to preserve the relationship it could have with the other variables.\n",
    "Now that we verified the columns have no missing value, we can move onto transforming the categorical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4.99769</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age    Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42   2.00000       0.00              1          1   \n",
       "1             608   41   1.00000   83807.86              1          0   \n",
       "2             502   42   8.00000  159660.80              3          1   \n",
       "3             699   39   1.00000       0.00              2          0   \n",
       "4             850   43   2.00000  125510.82              1          1   \n",
       "...           ...  ...       ...        ...            ...        ...   \n",
       "9995          771   39   5.00000       0.00              2          1   \n",
       "9996          516   35  10.00000   57369.61              1          1   \n",
       "9997          709   36   7.00000       0.00              1          0   \n",
       "9998          772   42   3.00000   75075.31              2          1   \n",
       "9999          792   28   4.99769  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform categorical columns -- Gender and Geography \n",
    "\n",
    "df = pd.get_dummies(df, columns = ['Geography', 'Gender'], drop_first = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using One Hot Encoding on categorial columns Geography and Gender, the resulting dataframe is printed and we see new columns 'Geography_Germany', 'Geography_Spain', and 'Gender_Male'. Geography_France and Gender_Female are implied from those columns. We decided to use OHE to transform those columns beacuse the rest of the data is in numerical form and possibly can interfer or may not even be suitable for direct use when attempting to train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we printed and examined the total number of 0s and 1s for the Exited column. in the context of the project, this means 7,963 clients are still with Beta Bank and 2,037 clients has terminated contract with Beta Bank. So there is a class imbalance since there is way more 0 answers than 1 and we will have to consider that when running and training the models. We can consider upsampling the minority class, which is 1 (clients who have exited) and making more instances of it so the amount of instances for '0' and '1' are more balance. Alternatively, we can go with downsampling where we will random discard some instances of '0's so that the differences between the two class is reduced. We should try both techniques on the models we will be building to see which one will give us the best score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset now for training set, validatin set, and testing set \n",
    "\n",
    "features = df.drop(['Exited'], axis = 1) \n",
    "target = df['Exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size = 0.4, random_state = 12345 ) #splitting into training and validation set\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size = 0.5, random_state = 12345) #splitting into validation and testing sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting ready to build and train our models, df is split into training, validation and testing sets, 60% of the data is alloted for training and the resulting 40% is split evenly into validiation sets and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validaton set:\n",
      "F1: 0.49166666666666664\n",
      "AUC-ROC: 0.7537231050272503\n"
     ]
    }
   ],
   "source": [
    "#logistic regression model \n",
    "\n",
    "model = LogisticRegression(random_state=12345, \n",
    "                           solver='liblinear', \n",
    "                           class_weight = 'balanced')\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "predicted_valid_proba = model.predict_proba(features_valid)[:, 1]\n",
    "#using predict_proba for calculating probabilities of the positive class('1' in this case, clients leaving) for AUC-ROC\n",
    "\n",
    "\n",
    "print('Validaton set:')\n",
    "print('F1:', f1_score(target_valid, predicted_valid))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_valid_proba)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first machine learning model we build is a Logistic Regression model and we added random state for reproducibilty and set class_weight to 'balanced' to help mitigate the class imbalance. \n",
    "we trained the LR model with the training dataset then use the model to predict target with the validation set. F1 score is 0.49 which fails to meet our project threshold F1 score of 0.59, so right off the bat we know this model is not good enough. \n",
    "With the F1 score being low at 0.45, it means that our model has low precision/recall so it is making many false positives predictions (saying a client will leave but actually does) or missing too many true positive predictions (saying a client will stay but actually leaves). AUC-ROC score is 0.75 which is decent and means that the model is able to distingush between clients who will leave soon and those who won't. Dispite that, the F1 score tells us that the model is making lots of false predictions. \n",
    "We will definately need to work on improveing the model, so we will focus on class weight imbalance issue with upsampling or downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n",
      "F1: 0.4512489927477841\n",
      "AUC-ROC: 0.7202726244412317\n"
     ]
    }
   ],
   "source": [
    "#logistic model with upsampling \n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "\n",
    "model_up = LogisticRegression(random_state=12345, \n",
    "                           solver='liblinear')\n",
    "\n",
    "model_up.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid_up = model_up.predict(features_valid) #f1 calculation\n",
    "\n",
    "predicted_valid_up_proba = model_up.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "print('Validation set:')\n",
    "print('F1:', f1_score(target_valid, predicted_valid_up))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_valid_up_proba))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code chunk, we created an upsample function that takes feature and target data and separate them into minority and majority classes, then we upsampled the data by concatenating the minority class 'repeat' number of times with the majority class; we saved those upsampled data in new variables \"features_upsampled\" and \"target_upsampled\". We then shuffle the upsampled data with random_state = 12345 for reproducibility. \n",
    "After creating the function we call it with the training dataset and repeat value of 4(we manually played around with different values) and save that generate data in \"features_upsampled\" and \"target_upsampled\" variables which will now be used for model training. We train the LR model with fit method and the upsampled data. We then use the model to make predictions on the validation set data. \n",
    "The resulting F1 score and AUC_ROC score is 0.45 and 0.72, respectively. This model with upsampled data is still not meeting our criteria and is performing worst than our previous LR model without upsampling. \n",
    "We will downsample the dataset next to see if there is any improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4601449275362319\n",
      "AUC-ROC: 0.7152837846829463\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with downsampling \n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)]+ [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.3)\n",
    "\n",
    "model_down = LogisticRegression(random_state=12345, \n",
    "                           solver='liblinear')\n",
    "\n",
    "model_down.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid_down = model_down.predict(features_valid) \n",
    "predicted_test_down = model_down.predict(features_test) \n",
    "\n",
    "predicted_valid_down_proba = model_down.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid_down))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_valid_down_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above codes we trained the LR model with downsampling technigue to hope balance the classes more and return a better F1 score. The downsample function takes features, target, and fraction parameter that specify the fraction of majority class to use. Similar to upsampling, the function separates the feature and target variables for the two classes and randomly samples a fraction of the majority class. The data is then shuffled and returned. \n",
    "We call the function with the \"features_downsampled\" and 'target_downsampled' data with a fraction of 0.3. \n",
    "We train the LR model with the downsampled data and then used the trained model to make predictions on the validation set. We are returned with F1 score of 0.46 and AU-ROC of 0.71. \n",
    "Alas none of the Logistic Regression models obtained a F1 score close to our project of 0.59. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n",
      "F1: 0.6245847176079734\n",
      "AUC-ROC: 0.8496270846061252\n"
     ]
    }
   ],
   "source": [
    "#randomforestclassifier \n",
    "\n",
    "model_RFC = RandomForestClassifier(random_state = 12345, \n",
    "                                   class_weight = 'balanced', \n",
    "                                   n_estimators = 100, \n",
    "                                   min_samples_split = 30,\n",
    "                                   )\n",
    "model_RFC.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "predicted_RFC_valid = model_RFC.predict(features_valid)\n",
    "predicted_RFC_valid_proba = model_RFC.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "\n",
    "print('Validation set:')\n",
    "print('F1:', f1_score(target_valid, predicted_RFC_valid))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_RFC_valid_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a RandomForestClassifier model to predict the target. We set random_state for reproducibility and balanced class weight, 30 minimum sample splits and n_estimator set to 100. The RFC model is then trained with the training set with fit method and used to make predictions on the validation set. We get an F1 score of 0.63 and AUC-ROC of 0.77, which does pass our threshold F1 score of 0.59 for this project! This means that the model is doing reasonably well. A perfect AUC-ROC score is 1 and our score of 0.84 is indicating that the model's predictive performance is pretty good at distingushing between the clients that will leave and will stay; it is correctly assigning higher predicted probabilities to the right clients (those who will leave), showing that the model is effective in distingushing between those who are likely to leave. \n",
    "\n",
    "Although this model is good, we want to explore if upsampling/downsampling will improve it even more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6258351893095768\n",
      "AUC-ROC: 0.8479394382980783\n"
     ]
    }
   ],
   "source": [
    "#randomforestclassifier with upsampling \n",
    "\n",
    "def upsample_RFC(features, target, repeat):\n",
    "    features_RFC_zeros = features[target == 0]\n",
    "    features_RFC_ones = features[target == 1]\n",
    "    target_RFC_zeros = target[target == 0]\n",
    "    target_RFC_ones = target[target == 1]\n",
    "\n",
    "    features_RFC_upsampled = pd.concat([features_RFC_zeros] + [features_RFC_ones] * repeat)\n",
    "    target_RFC_upsampled = pd.concat([target_RFC_zeros] + [target_RFC_ones] * repeat)\n",
    "\n",
    "    features_RFC_upsampled, target_RFC_upsampled = shuffle(features_RFC_upsampled, target_RFC_upsampled, random_state=12345)\n",
    "\n",
    "    return features_RFC_upsampled, target_RFC_upsampled\n",
    "\n",
    "features_RFC_upsampled, target_RFC_upsampled = upsample_RFC(features_train, target_train, 4)\n",
    "\n",
    "model_RFC_up = RandomForestClassifier(random_state = 12345, \n",
    "                                   n_estimators = 100,\n",
    "                                   min_samples_split = 30,\n",
    "                                   )\n",
    "model_RFC_up.fit(features_RFC_upsampled, target_RFC_upsampled)\n",
    "predicted_RFC_valid_up = model_RFC_up.predict(features_valid)\n",
    "\n",
    "predicted_RFC_valid_up_proba = model_RFC_up.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_RFC_valid_up))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_RFC_valid_up_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we did with upsampling the data for LR model, we created a upsample_RFC function that will separate the classes into minority and majority and then we upsampled the data by concatenating the minior class and then shuffled the data so that the model doesn't know the data. We called the upsampled_RFC function on training set and repeated it 4 times like previously. We made predictions on the validation set. \n",
    "We get a F1 score of 0.625 and AUC-ROC of 0.847, which is essentially the same as our RFC model without upsampling but weight_class set to 'balanced'. \n",
    "This model performs similarly with approx. 62% of correct predictions for the positive (clients leaving) class. We still have a AUC-ROC of 0.84 so the model has the ability to identify the clients who have left and those who hasn't. \n",
    "Overall, pretty decent model but does not give a better result than RFC without upsampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6134969325153374\n",
      "AUC-ROC: 0.8510243831622498\n"
     ]
    }
   ],
   "source": [
    "#randomforestclassifier with downsampling \n",
    "\n",
    "def downsample_RFC(features, target, fraction):\n",
    "    features_RFC_zeros = features[target == 0]\n",
    "    features_RFC_ones = features[target == 1]\n",
    "    target_RFC_zeros = target[target == 0]\n",
    "    target_RFC_ones = target[target == 1]\n",
    "\n",
    "    features_RFC_downsampled = pd.concat([features_RFC_zeros.sample(frac=fraction, random_state=12345)]+ [features_RFC_ones])\n",
    "    target_RFC_downsampled = pd.concat([target_RFC_zeros.sample(frac=fraction, random_state=12345)] + [target_RFC_ones])\n",
    "\n",
    "    features_RFC_downsampled, target_RFC_downsampled = shuffle(features_RFC_downsampled, target_RFC_downsampled, random_state=12345)\n",
    "\n",
    "    return features_RFC_downsampled, target_RFC_downsampled\n",
    "\n",
    "features_RFC_downsampled, target_RFC_downsampled = downsample_RFC(features_train, target_train, 0.3)\n",
    "\n",
    "model_RFC_down = RandomForestClassifier(random_state = 12345, \n",
    "                                   n_estimators = 100,\n",
    "                                   min_samples_split = 30,\n",
    "                                   )\n",
    "\n",
    "model_RFC_down.fit(features_RFC_downsampled, target_RFC_downsampled)\n",
    "predicted_RFC_valid_down = model_RFC_down.predict(features_valid)\n",
    "\n",
    "predicted_RFC_valid_down_proba = model_RFC_down.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_RFC_valid_down))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_RFC_valid_down_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we created a RFC with downsampling on the target and features variable. In the downsample_RFC function we created two separate dataset for the two class and then it samples a fraction of the majority class ('1' clients who stay) to help balance the dataset. We initialized the model with the same hyperparameters and the model is trained on the downsampled data. We make predictions on the validation set and print the F1 and AUC-ROC score. \n",
    "We obtained a F1 score of 0.61 and AUC-ROC of 0.85, which is lower than the F1 score we obtained with RFC model and RFC_model with upsampling. This model performs relatively similarly like the others but not the best of the RFC models. It still passes the threshold of 0.59 which means it's ability to identify clients who left or not is reasonably well, but it is predicting less accurately than previous two. The AUC-ROC score is better, ever so slightly, than the other two RFC models as well but overall not the bestest. \n",
    "We will create DecisionTree models to explore how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5551330798479086\n",
      "AUC-ROC: 0.8125654038555762\n"
     ]
    }
   ],
   "source": [
    "#decicisonttreeclassifier \n",
    "\n",
    "model_DTC = DecisionTreeClassifier(random_state = 12345, \n",
    "                                   class_weight = 'balanced', \n",
    "                                   min_samples_split = 100)\n",
    "\n",
    "model_DTC.fit(features_train, target_train)\n",
    "predicted_DTC_valid = model_DTC.predict(features_valid)\n",
    "\n",
    "predicted_DTC_valid_proba = model_DTC.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_DTC_valid))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_DTC_valid_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above we created a DecisonTreeClassifier model with hyperparameters random_state = 12345 for reproduciability, class weight to 'balanced' and min_sample_split to 100 since we found it to return a higher f1 score when manually tuning the hyperparameters. We train the model with the training set and made predictions with the validation set. \n",
    "The F1 score for this model is 0.55 and AUC-ROC of 0.81, the F1 score falls short of the threshold of 0.59 so this model does not pass. However, the model is performing well in terms of distingushing between those who will leave and those who will stay. \n",
    "We will create models with up and downsampling techinques to explore if it improves the F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5473684210526316\n",
      "AUC-ROC: 0.7858949969452996\n"
     ]
    }
   ],
   "source": [
    "#decisiontreeclassifier with upsampling \n",
    "\n",
    "def upsample_DTC(features, target, repeat):\n",
    "    features_DTC_zeros = features[target == 0]\n",
    "    features_DTC_ones = features[target == 1]\n",
    "    target_DTC_zeros = target[target == 0]\n",
    "    target_DTC_ones = target[target == 1]\n",
    "\n",
    "    features_DTC_upsampled = pd.concat([features_DTC_zeros] + [features_DTC_ones] * repeat)\n",
    "    target_DTC_upsampled = pd.concat([target_DTC_zeros] + [target_DTC_ones] * repeat)\n",
    "\n",
    "    features_DTC_upsampled, target_DTC_upsampled = shuffle(features_DTC_upsampled, target_DTC_upsampled, random_state=12345)\n",
    "\n",
    "    return features_DTC_upsampled, target_DTC_upsampled\n",
    "\n",
    "features_DTC_upsampled, target_DTC_upsampled = upsample_DTC(features_train, target_train, 4)\n",
    "\n",
    "\n",
    "model_DTC_up = DecisionTreeClassifier(random_state = 12345, min_samples_split = 100)\n",
    "model_DTC_up.fit(features_DTC_upsampled, target_DTC_upsampled)\n",
    "predicted_DTC_valid_up = model_DTC_up.predict(features_valid)\n",
    "\n",
    "predicted_DTC_valid_up_proba = model_DTC_up.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_DTC_valid_up))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_DTC_valid_up_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a upsample_DTC function that will upsample the miniority class, clients who left, replicate it 'repeat' (4) number of times and shuffle it. the upsampled data is then used to train the DecisionTree model with the same hyperparameters except weight class. After training we make predictions on the validation set and calculated the F1 and AUC-ROC metric. \n",
    "We get a F1 score of 0.54 and AUC-ROC of 0.78, which still falls short of passing our threshold.\n",
    "We will create the last model to see if that will produce a F1 score that passes the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5764023210831721\n",
      "AUC-ROC: 0.812093588758703\n"
     ]
    }
   ],
   "source": [
    "#decision tree classifier with downsampling \n",
    "\n",
    "def downsample_DTC(features, target, repeat):\n",
    "    features_DTC_zeros = features[target == 0]\n",
    "    features_DTC_ones = features[target == 1]\n",
    "    target_DTC_zeros = target[target == 0]\n",
    "    target_DTC_ones = target[target == 1]\n",
    "\n",
    "    features_DTC_downsampled = pd.concat([features_DTC_zeros.sample(frac=repeat, random_state=12345)]+ [features_DTC_ones])\n",
    "    target_DTC_downsampled = pd.concat([target_DTC_zeros.sample(frac=repeat, random_state=12345)] + [target_DTC_ones])\n",
    "\n",
    "    features_DTC_downsampled, target_DTC_downsampled = shuffle(features_DTC_downsampled, target_DTC_downsampled, random_state=12345)\n",
    "\n",
    "    return features_DTC_downsampled, target_DTC_downsampled\n",
    "\n",
    "features_DTC_downsampled, target_DTC_downsampled = downsample_DTC(features_train, target_train, .3)\n",
    "\n",
    "model_DTC_down = DecisionTreeClassifier(random_state = 12345, min_samples_split = 100)\n",
    "model_DTC_down.fit(features_DTC_downsampled, target_DTC_downsampled)\n",
    "\n",
    "predicted_DTC_valid_down = model_DTC_down.predict(features_valid)\n",
    "predicted_DTC_test_down = model_DTC_down.predict(features_test) #making predictions on testing set, will be call on to calculate F1/AUC-ROC\n",
    "\n",
    "predicted_DTC_test_down_proba = model_DTC_down.predict_proba(features_valid)[:, 1] #probs of 1 for auc-roc\n",
    "\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_DTC_valid_down))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, predicted_DTC_test_down_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created function downsampled_DTC to take features and target and repeat parameter which will be the ratio of classes after downsampling. The function downsamples the data by randomly selecting a fraction (repeat) of the majority class (clients who stay) and concatenating them with all of the minority class. It is then shuffled for better usage. the downsampled_DTC function is called on to downsample the training set. the model is then trained with the downsample data. The model is used to make predictions on the validation set and F1 and AUC-ROC metrics are calcuated to evalute how well this model is. F1 score of 0.57 and AUC-ROC score of 0.81; which is so close to meeting our criteria of F1 score of at least 0.59. \n",
    "\n",
    "DecisionTree models is not the best model to use in this project since we know that the RandomForestClassifier models have f1 scores > 0.59 on their validation set; however, DecisionTreeClassifier models did perform better than Logistic Regression models in terms of F1 score. \n",
    "\n",
    "So, the last thing to do is perform final testing with the model that returned the best F1 score from validation set -- RandomForestClassifier with upsampling technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC model with upsampling:  F1 =  0.62  |  AUC-ROC = 0.86\n"
     ]
    }
   ],
   "source": [
    "#Final testing \n",
    "\n",
    "predicted_RFC_test_up = model_RFC_up.predict(features_test)\n",
    "predicted_RFC_test_up_proba = model_RFC_up.predict_proba(features_test)[:, 1] \n",
    "\n",
    "print(\"RFC model with upsampling: \", \"F1 = \", round(f1_score(target_test, predicted_RFC_test_up), 2), \" | \", \n",
    "      \"AUC-ROC =\", round(roc_auc_score(target_test, predicted_RFC_test_up_proba), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We printed the F1 and AUC-ROC score for testing sets for the RandomForestClassifier model with upsampling and obstained:F1 = 0.62 and AUC-ROC = 0.86. These scores indicate that the model is performing reasonably well and exceeds our projects threshold of 0.59 F1 score on the testing set. The model achieved reasonable accuracy of 62% in predicting clients who will leave, indicating it's pretty good at identifying clients who will leave. Additionally,the AUC-ROC score of 0.86 is relatively high since 1 is the perfect score, it suggest the the model is effective in differentiating the clients who will likely leave and those who will likely stay. \n",
    "\n",
    "In conclusion, RandomForestClassifier with upsampling proves to be the best choice of all our models built and that should be the model that Beta Bank should employ if there is class imbalance. It produces the highest F1 score and good AUC-ROC meaning the model is pretty good at predicting if a client will leave while minimizing false positives (indicating a client will leave but actually stay). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
